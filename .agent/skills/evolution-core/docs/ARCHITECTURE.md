# üìÑ Documenta√ß√£o da Arquitetura: Evolution Core

Este documento fornece uma vis√£o aprofundada da arquitetura da skill **Evolution Core**. Para um guia de uso r√°pido, consulte o arquivo `SKILL.md` principal.

## 1. Vis√£o Geral e Filosofia

A arquitetura do **Evolution Core** √© projetada para ser modular e resiliente, baseada em tr√™s pilares interdependentes:

1.  **Captura e Armazenamento**: Garante que nenhuma informa√ß√£o seja perdida.
2.  **Aprendizado e Evolu√ß√£o**: Transforma informa√ß√£o em conhecimento e melhoria cont√≠nua.
3.  **Comportamento Proativo**: Usa o conhecimento para agregar valor de forma aut√¥noma.

O fluxo de dados √© c√≠clico: o comportamento do agente gera novas observa√ß√µes, que s√£o capturadas e armazenadas. O sistema de aprendizado analisa essa mem√≥ria para evoluir o comportamento do agente, o que, por sua vez, leva a a√ß√µes mais inteligentes e proativas.

## 2. Detalhamento dos Componentes

### 2.1. Worker de Mem√≥ria (`scripts/worker.py`)

O cora√ß√£o do sistema de mem√≥ria. √â um servi√ßo **FastAPI** que fornece uma API para gerenciar o conhecimento do agente.

*   **Tecnologia**: Python, FastAPI, Uvicorn.
*   **Banco de Dados**: 
    *   **SQLite**: Para dados estruturados e metadados. Escolhido pela simplicidade e por n√£o exigir um servidor separado. A tabela `observations` armazena o JSON completo de cada evento capturado.
    *   **ChromaDB**: Para busca de similaridade vetorial. Permite a busca sem√¢ntica ("encontre-me observa√ß√µes sobre X") em vez de apenas busca por palavra-chave.
*   **Endpoints da API**:
    *   `POST /observations/`: Recebe uma nova observa√ß√£o do hook `PostToolUse`, a processa e a armazena nos dois bancos de dados.
    *   `GET /search/`: Recebe uma query de texto, a vetoriza e a usa para buscar as observa√ß√µes mais relevantes no ChromaDB.
    *   `GET /observations/{obs_id}`: Retorna o JSON completo de uma observa√ß√£o espec√≠fica, buscando pelo seu ID no SQLite.

### 2.2. Hooks de Ciclo de Vida

S√£o a ponte entre o agente e o sistema de mem√≥ria. S√£o scripts leves que s√£o acionados em pontos espec√≠ficos do ciclo de vida do agente.

*   **`post_tool_use_hook.py`**: 
    1.  Acionado ap√≥s cada uso de ferramenta.
    2.  Recebe o JSON da observa√ß√£o via `stdin`.
    3.  Chama um **LLM (via Perplexity API)** para gerar um t√≠tulo e um resumo sem√¢ntico da observa√ß√£o. Isso √© crucial para a busca sem√¢ntica posterior.
    4.  Envia o JSON enriquecido para o endpoint `POST /observations/` do worker de mem√≥ria.
    5.  √â projetado para falhar silenciosamente (logando em `/tmp/`) para n√£o interromper o fluxo do agente se o worker ou a API do LLM estiverem indispon√≠veis.
*   **`heartbeat.py`**: 
    1.  Acionado pelo hook `Stop` (no final de uma intera√ß√£o) ou por um cron.
    2.  Executa o checklist de `HEARTBEAT.md`.
    3.  A l√≥gica de proatividade tamb√©m usa o LLM para gerar sugest√µes contextuais.

### 2.3. Scripts de Aprendizado (Batch)

Estes scripts rodam de forma ass√≠ncrona para processar a mem√≥ria e gerar aprendizados de longo prazo.

*   **`nightly_review.py`**: 
    1.  Projetado para ser executado por um **cron job** toda noite.
    2.  Conecta-se ao banco de dados SQLite e busca todas as observa√ß√µes do dia anterior.
    3.  Envia os t√≠tulos e resumos para um LLM com um prompt para sintetizar os aprendizados chave do dia.
    4.  Anexa essa s√≠ntese ao arquivo `MEMORY.md`, criando um registro cont√≠nuo de evolu√ß√£o.

## 3. Fluxo de Dados Detalhado

```mermaid
sequenceDiagram
    participant Agente
    participant Hook_PostToolUse
    participant LLM_API
    participant Worker_Memoria
    participant SQLite
    participant ChromaDB

    Agente->>+Hook_PostToolUse: Executa ferramenta e envia observa√ß√£o (stdin)
    Hook_PostToolUse->>+LLM_API: Envia observa√ß√£o para sumariza√ß√£o
    LLM_API-->>-Hook_PostToolUse: Retorna {t√≠tulo, resumo}
    Hook_PostToolUse->>+Worker_Memoria: POST /observations/ (JSON enriquecido)
    Worker_Memoria->>+SQLite: INSERT INTO observations ...
    SQLite-->>-Worker_Memoria: Retorna obs_id
    Worker_Memoria->>+ChromaDB: add(document=resumo, id=obs_id)
    ChromaDB-->>-Worker_Memoria: Confirma√ß√£o
    Worker_Memoria-->>-Hook_PostToolUse: status 201 Created
    Hook_PostToolUse-->>-Agente: Finaliza execu√ß√£o
```

## 4. Instala√ß√£o e Depend√™ncias

O script `scripts/install.sh` automatiza a configura√ß√£o do ambiente.

*   **Depend√™ncias de Sistema**: `python3-pip`.
*   **Depend√™ncias Python**: 
    *   `fastapi` / `uvicorn`: Para o worker de mem√≥ria.
    *   `chromadb` / `pysqlite3-binary`: Para os bancos de dados.
    *   `requests`: Para a comunica√ß√£o com a API do LLM.
    *   `python-dotenv`: Para o gerenciamento de chaves de API e configura√ß√µes.

## 5. Considera√ß√µes de Design

*   **Modularidade**: Cada componente (worker, hooks, scripts) √© independente e se comunica por APIs REST ou chamadas de shell, facilitando a manuten√ß√£o e a substitui√ß√£o.
*   **Resili√™ncia**: Os hooks s√£o projetados para n√£o travar o agente. Se o sistema de mem√≥ria estiver offline, o agente continua funcionando, embora sem a capacidade de aprendizado.
*   **Efici√™ncia**: A sumariza√ß√£o no momento da captura (`PostToolUse`) distribui a carga de processamento do LLM ao longo do tempo, em vez de sobrecarregar o sistema durante a revis√£o noturna. A busca vetorial garante que a recupera√ß√£o da mem√≥ria seja r√°pida, mesmo com um grande volume de dados.
*   **Simplicidade**: O uso de SQLite e ChromaDB (com persist√™ncia em arquivo) elimina a necessidade de servidores de banco de dados complexos, tornando a configura√ß√£o mais simples e port√°til.
